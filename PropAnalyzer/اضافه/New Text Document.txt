Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¨Ø§ Ø¨Ø®Ø´ 1ï¸âƒ£: Backend (Django API) â€” Ù‡Ø³ØªÙ‡â€ŒÛŒ Ø§ØµÙ„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡.


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/backend/

manage.py

#!/usr/bin/env python
import os
import sys

def main():
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'propanalyzer_api.settings')
    from django.core.management import execute_from_command_line
    execute_from_command_line(sys.argv)

if name == 'main':
    main()


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/backend/propanalyzer_api/settings.py

import os
from pathlib import Path

BASE_DIR = Path(file).resolve().parent.parent
SECRET_KEY = 'change-me'
DEBUG = True
ALLOWED_HOSTS = ['*']

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'rest_framework',
    'corsheaders',
    'apps.listings',
    'apps.users',
    'apps.analytics',
    'apps.dashboard',
]

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'propanalyzer_api.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [BASE_DIR / 'templates'],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'propanalyzer_api.wsgi.application'

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('POSTGRES_DB', 'propanalyzer_db'),
        'USER': os.getenv('POSTGRES_USER', 'propanalyst'),
        'PASSWORD': os.getenv('POSTGRES_PASSWORD', 'password'),
        'HOST': os.getenv('POSTGRES_HOST', 'db'),
        'PORT': 5432,
    }
}

AUTH_PASSWORD_VALIDATORS = []
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'Asia/Tehran'
USE_I18N = True
USE_TZ = True
STATIC_URL = '/static/'
DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/backend/propanalyzer_api/urls.py

from django.contrib import admin
from django.urls import path, include

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/listings/', include('apps.listings.urls')),
    path('api/users/', include('apps.users.urls')),
    path('api/analytics/', include('apps.analytics.urls')),
    path('api/dashboard/', include('apps.dashboard.urls')),
]


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/backend/propanalyzer_api/wsgi.py

import os
from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'propanalyzer_api.settings')
application = get_wsgi_application()


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/backend/propanalyzer_api/apps/listings/models.py

from django.db import models

class Listing(models.Model):
    title = models.CharField(max_length=200)
    address = models.CharField(max_length=255)
    price = models.BigIntegerField()
    area = models.FloatField()
    year_built = models.IntegerField()
    city = models.CharField(max_length=100)
    district = models.CharField(max_length=100)
    created_at = models.DateTimeField(auto_now_add=True)

    def str(self):
        return self.title


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/backend/propanalyzer_api/apps/listings/views.py

from rest_framework import viewsets
from .models import Listing
from .serializers import ListingSerializer

class ListingViewSet(viewsets.ModelViewSet):
    queryset = Listing.objects.all().order_by('-created_at')
    serializer_class = ListingSerializer


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/backend/propanalyzer_api/apps/listings/serializers.py

from rest_framework import serializers
from .models import Listing

class ListingSerializer(serializers.ModelSerializer):
    class Meta:
        model = Listing
        fields = 'all'


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/backend/propanalyzer_api/apps/listings/urls.py

from rest_framework.routers import DefaultRouter
from .views import ListingViewSet

router = DefaultRouter()
router.register('', ListingViewSet)

urlpatterns = router.urls


---

ğŸ§© Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Backend Django API




Ø®ÛŒÙ„ÛŒ Ø¹Ø§Ù„ÛŒ ğŸ˜
Ø¨Ø±ÛŒÙ… Ø³Ø±Ø§Øº Ø¨Ø®Ø´ Ø¯ÙˆÙ… Ù¾Ø±ÙˆÚ˜Ù‡:


---

ğŸ•·ï¸ Ø¨Ø®Ø´ 2ï¸âƒ£ â€” Crawler (Scrapy)

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/crawler/


---

scrapy.cfg

[settings]
default = crawler_app.settings


---

ğŸ“ Ù…Ø³ÛŒØ±: crawler_app/settings.py

BOT_NAME = "crawler_app"
SPIDER_MODULES = ["crawler_app.spiders"]
NEWSPIDER_MODULE = "crawler_app.spiders"

ROBOTSTXT_OBEY = False
DOWNLOAD_DELAY = 1.5
CONCURRENT_REQUESTS = 4

ITEM_PIPELINES = {
    "crawler_app.pipelines.SaveToPostgresPipeline": 300,
}


---

ğŸ“ Ù…Ø³ÛŒØ±: crawler_app/items.py

import scrapy

class PropertyItem(scrapy.Item):
    title = scrapy.Field()
    address = scrapy.Field()
    price = scrapy.Field()
    area = scrapy.Field()
    year_built = scrapy.Field()
    city = scrapy.Field()
    district = scrapy.Field()


---

ğŸ“ Ù…Ø³ÛŒØ±: crawler_app/pipelines.py

import psycopg2
from scrapy.exceptions import DropItem
import os

class SaveToPostgresPipeline:
    def open_spider(self, spider):
        self.conn = psycopg2.connect(
            host=os.getenv('POSTGRES_HOST', 'db'),
            dbname=os.getenv('POSTGRES_DB', 'propanalyzer_db'),
            user=os.getenv('POSTGRES_USER', 'propanalyst'),
            password=os.getenv('POSTGRES_PASSWORD', 'password')
        )
        self.cur = self.conn.cursor()

    def process_item(self, item, spider):
        self.cur.execute("""
            INSERT INTO backend_propanalyzer_api_listing (title, address, price, area, year_built, city, district, created_at)
            VALUES (%s,%s,%s,%s,%s,%s,%s,NOW())
        """, (
            item['title'], item['address'], item['price'],
            item['area'], item['year_built'], item['city'], item['district']
        ))
        self.conn.commit()
        return item

    def close_spider(self, spider):
        self.cur.close()
        self.conn.close()


---

ğŸ“ Ù…Ø³ÛŒØ±: crawler_app/spiders/divar_spider.py

import scrapy
from crawler_app.items import PropertyItem

class DivarSpider(scrapy.Spider):
    name = "divar"
    start_urls = ["https://divar.ir/s/tehran"]

    def parse(self, response):
        for item in response.css("div.kt-post-card"):
            yield PropertyItem(
                title=item.css("h2.kt-post-card__title::text").get(),
                address=item.css("div.kt-post-card__bottom-description::text").get(),
                price=item.css("span.kt-post-card__price::text").get(),
                area=None,
                year_built=None,
                city="ØªÙ‡Ø±Ø§Ù†",
                district="Ù†Ø§Ù…Ø´Ø®Øµ",
            )


---

ğŸ“ Ù…Ø³ÛŒØ±: crawler_app/spiders/sheypoor_spider.py

import scrapy
from crawler_app.items import PropertyItem

class SheypoorSpider(scrapy.Spider):
    name = "sheypoor"
    start_urls = ["https://www.sheypoor.com/s/%D8%AA%D9%87%D8%B1%D8%A7%D9%86"]

    def parse(self, response):
        for item in response.css(".content-box"):
            yield PropertyItem(
                title=item.css("h2::text").get(),
                address=None,
                price=item.css(".price::text").get(),
                area=None,
                year_built=None,
                city="ØªÙ‡Ø±Ø§Ù†",
                district="Ù†Ø§Ù…Ø´Ø®Øµ",
            )


---

ğŸ“ Ù…Ø³ÛŒØ±: crawler_app/spiders/ihome_spider.py

import scrapy
from crawler_app.items import PropertyItem

class IHomeSpider(scrapy.Spider):
    name = "ihome"
    start_urls = ["https://ihome.ir/sell/tehran"]

def parse(self, response):
        for item in response.css(".property-item"):
            yield PropertyItem(
                title=item.css(".title::text").get(),
                address=item.css(".address::text").get(),
                price=item.css(".price::text").get(),
                area=item.css(".area::text").get(),
                year_built=None,
                city="ØªÙ‡Ø±Ø§Ù†",
                district="Ù†Ø§Ù…Ø´Ø®Øµ",
            )


---

ğŸ“„ Dockerfile

FROM python:3.11
WORKDIR /app
COPY . .
RUN pip install scrapy psycopg2-binary
CMD ["scrapy", "crawl", "divar"]


---

ğŸ§© Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Crawler (Scrapy)





Ø®ÛŒÙ„ÛŒ Ø¹Ø§Ù„ÛŒ ğŸ˜
Ø§Ù„Ø§Ù† Ù…ÛŒâ€ŒØ±ÛŒÙ… Ø³Ø±Ø§Øº Ø¨Ø®Ø´ Ø³ÙˆÙ… Ù¾Ø±ÙˆÚ˜Ù‡:


---

ğŸ¤– Ø¨Ø®Ø´ 3ï¸âƒ£ â€” AI (FastAPI + Ù…Ø¯Ù„ ØªØ­Ù„ÛŒÙ„ Ù‚ÛŒÙ…Øª)

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/ai/


---

app/main.py

from fastapi import FastAPI
from .routers import predict, analyze, undervalued

app = FastAPI(title="PropAnalyzer AI API", version="1.0")

app.include_router(predict.router)
app.include_router(analyze.router)
app.include_router(undervalued.router)

@app.get("/")
def root():
    return {"message": "PropAnalyzer AI API is running"}


---

ğŸ“ Ù…Ø³ÛŒØ±: app/db.py

import psycopg2, os

def get_db_connection():
    return psycopg2.connect(
        host=os.getenv('POSTGRES_HOST', 'db'),
        dbname=os.getenv('POSTGRES_DB', 'propanalyzer_db'),
        user=os.getenv('POSTGRES_USER', 'propanalyst'),
        password=os.getenv('POSTGRES_PASSWORD', 'password')
    )


---

ğŸ“ Ù…Ø³ÛŒØ±: app/models/ai_model.py

import pickle, os, pandas as pd
from sklearn.linear_model import LinearRegression

MODEL_PATH = "model.pkl"

def train_model(data: pd.DataFrame):
    X = data[['area', 'year_built']]
    y = data['price']
    model = LinearRegression().fit(X, y)
    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(model, f)
    return model

def load_model():
    if not os.path.exists(MODEL_PATH):
        return None
    with open(MODEL_PATH, 'rb') as f:
        return pickle.load(f)

def predict_price(area, year_built):
    model = load_model()
    if model is None:
        return None
    return float(model.predict([[area, year_built]])[0])


---

ğŸ“ Ù…Ø³ÛŒØ±: app/utils/preprocessing.py

import pandas as pd

def clean_data(df: pd.DataFrame):
    df = df.dropna(subset=["price", "area"])
    df["price_per_m2"] = df["price"] / df["area"]
    return df


---

ğŸ“ Ù…Ø³ÛŒØ±: app/routers/predict.py

from fastapi import APIRouter
from ..models.ai_model import predict_price

router = APIRouter(prefix="/predict", tags=["Prediction"])

@router.get("/")
def predict(area: float, year_built: int):
    result = predict_price(area, year_built)
    return {"predicted_price": result}


---

ğŸ“ Ù…Ø³ÛŒØ±: app/routers/analyze.py

from fastapi import APIRouter
import pandas as pd
from ..utils.preprocessing import clean_data

router = APIRouter(prefix="/analyze", tags=["Analysis"])

@router.post("/")
def analyze_market(data: list[dict]):
    df = pd.DataFrame(data)
    cleaned = clean_data(df)
    avg_price = cleaned["price_per_m2"].mean()
    return {"avg_price_per_m2": avg_price, "records": len(cleaned)}


---

ğŸ“ Ù…Ø³ÛŒØ±: app/routers/undervalued.py

from fastapi import APIRouter
import pandas as pd

router = APIRouter(prefix="/undervalued", tags=["Investment"])

@router.post("/")
def find_undervalued(data: list[dict]):
    df = pd.DataFrame(data)
    avg = df["price"].mean()
    undervalued = df[df["price"] < 0.8 * avg].to_dict(orient="records")
    return {"undervalued_properties": undervalued}


---

ğŸ“„ requirements.txt

fastapi
uvicorn
pandas
scikit-learn
psycopg2-binary


---

ğŸ“„ Dockerfile

FROM python:3.11
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
EXPOSE 8001
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8001"]


---

ğŸ§© Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ AI (FastAPI + ML)


Ø®ÛŒÙ„ÛŒ Ø¹Ø§Ù„ÛŒ ğŸ’ª
Ø¨Ø±ÛŒÙ… Ø³Ø±Ø§Øº Ø¨Ø®Ø´ Ú†Ù‡Ø§Ø±Ù… Ù¾Ø±ÙˆÚ˜Ù‡ â€” Ø¨Ø®Ø´ Frontend (Next.js + Tailwind CSS).
Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù…Ø¯Ø±Ù† Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø³Øª.


---

ğŸ’» Ø¨Ø®Ø´ 4ï¸âƒ£ â€” Frontend (Next.js + Tailwind)

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/frontend/


---

package.json

{
  "name": "propanalyzer-frontend",
  "version": "1.0.0",
  "private": true,
  "scripts": {
    "dev": "next dev -p 3000",
    "build": "next build",
    "start": "next start"
  },
  "dependencies": {
    "next": "14.0.0",
    "react": "18.2.0",
    "react-dom": "18.2.0",
    "axios": "^1.6.0",
    "recharts": "^2.10.0",
    "tailwindcss": "^3.3.0"
  }
}


---

next.config.js

/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  images: { domains: ['localhost'] },
};
module.exports = nextConfig;


---

tailwind.config.js

module.exports = {
  content: ['./pages//*.{js,jsx}', './components//*.{js,jsx}'],
  theme: { extend: {} },
  plugins: [],
};


---

styles/globals.css

@tailwind base;
@tailwind components;
@tailwind utilities;

body {
  @apply bg-white text-gray-800;
  font-family: sans-serif;
}


---

ğŸ“ Ù…Ø³ÛŒØ±: pages/_app.js

import '@/styles/globals.css'
import Navbar from '@/components/Navbar'
import Footer from '@/components/Footer'

export default function App({ Component, pageProps }) {
  return (
    <>
      <Navbar />
      <main className="min-h-screen p-4">
        <Component {...pageProps} />
      </main>
      <Footer />
    </>
  )
}


---

ğŸ“ Ù…Ø³ÛŒØ±: pages/index.js

import axios from 'axios'
import PropertyCard from '@/components/PropertyCard'

export default function Home({ listings }) {
  return (
    <div className="container mx-auto">
      <h1 className="text-3xl font-bold mb-6 text-blue-600">PropAnalyzer</h1>
      <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
        {listings.map((p, i) => (
          <PropertyCard key={i} property={p} />
        ))}
      </div>
    </div>
  )
}

export async function getServerSideProps() {
  const res = await axios.get('http://localhost:8000/api/listings/')
  return { props: { listings: res.data } }
}


---

ğŸ“ Ù…Ø³ÛŒØ±: pages/about.js

export default function About() {
  return (
    <div className="p-8">
      <h1 className="text-2xl font-bold text-blue-600 mb-4">Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ø§</h1>
      <p>ØªØ­Ù„ÛŒÙ„â€ŒÙ…Ù„Ú© Ø¨Ø§ Ù‡Ø¯Ù Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ù…Ø³Ú©Ù† Ø§ÛŒØ±Ø§Ù† Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.</p>
    </div>
  )
}


---

ğŸ“ Ù…Ø³ÛŒØ±: pages/listings/[id].js

import axios from 'axios'

export default function Listing({ listing }) {
  return (
    <div className="p-8">
      <h1 className="text-2xl font-bold">{listing.title}</h1>
      <p>Ø¢Ø¯Ø±Ø³: {listing.address}</p>
      <p>Ù‚ÛŒÙ…Øª: {listing.price.toLocaleString()} ØªÙˆÙ…Ø§Ù†</p>
      <p>Ù…ØªØ±Ø§Ú˜: {listing.area} Ù…ØªØ±</p>
    </div>
  )
}

export async function getServerSideProps({ params }) {
  const res = await axios.get(http://localhost:8000/api/listings/${params.id}/)
  return { props: { listing: res.data } }
}


---

ğŸ“ Ù…Ø³ÛŒØ±: pages/dashboard.js

import { useEffect, useState } from 'react'
import axios from 'axios'
import Charts from '@/components/Charts'

export default function Dashboard() {
  const [data, setData] = useState([])

  useEffect(() => {
    axios.get('http://localhost:8001/analyze')
      .then(res => setData(res.data))
      .catch(() => {})
  }, [])

  return (
    <div className="p-8">
      <h1 className="text-2xl font-bold text-blue-600 mb-4">Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„</h1>
      <Charts data={data} />
    </div>
  )
}


---

ğŸ“ Ù…Ø³ÛŒØ±: components/Navbar.jsx

import Link from 'next/link'

export default function Navbar() {
  return (
    <nav className="bg-blue-600 text-white p-4 flex justify-between">
      <span className="font-bold">PropAnalyzer</span>
      <div className="space-x-4">
        <Link href="/">Ø®Ø§Ù†Ù‡</Link>
        <Link href="/about">Ø¯Ø±Ø¨Ø§Ø±Ù‡</Link>
        <Link href="/dashboard">Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯</Link>
      </div>
    </nav>
  )
}


---

ğŸ“ Ù…Ø³ÛŒØ±: components/Footer.jsx

export default function Footer() {
  return (
    <footer className="bg-gray-100 text-center p-4 mt-10 text-sm text-gray-500">
      Â© 2025 PropAnalyzer
    </footer>
  )
}


---

ğŸ“ Ù…Ø³ÛŒØ±: components/PropertyCard.jsx

export default function PropertyCard({ property }) {
  return (
    <div className="border rounded-xl p-4 shadow hover:shadow-lg transition">
      <h2 className="text-xl font-semibold">{property.title}</h2>
      <p>{property.address}</p>
      <p className="text-blue-600 font-bold mt-2">
        {property.price.toLocaleString()} ØªÙˆÙ…Ø§Ù†
      </p>
    </div>
  )
}


---

ğŸ“ Ù…Ø³ÛŒØ±: components/Charts.jsx

import { LineChart, Line, XAxis, YAxis, Tooltip, CartesianGrid, ResponsiveContainer } from 'recharts'

export default function Charts({ data }) {
  return (
    <div className="w-full h-80">
      <ResponsiveContainer>
        <LineChart data={data}>
          <CartesianGrid strokeDasharray="3 3" />
          <XAxis dataKey="month" />
          <YAxis />
          <Tooltip />
          <Line type="monotone" dataKey="avg_price" stroke="#2563eb" strokeWidth={2} />
        </LineChart>
      </ResponsiveContainer>
    </div>
  )
}


---

ğŸ§© Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Frontend (Next.js + Tailwind)



Ø¹Ø§Ù„ÛŒ ğŸ’ª
Ø­Ø§Ù„Ø§ Ø¨Ø±ÛŒÙ… Ø³Ø±Ø§Øº Ø¨Ø®Ø´ Ù¾Ø§ÛŒØ§Ù†ÛŒ Ùˆ Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù… Ù¾Ø±ÙˆÚ˜Ù‡ â€”
Ø¨Ø®Ø´ Ûµï¸âƒ£: Docker, Scripts Ùˆ Env Ù†Ù‡Ø§ÛŒÛŒ
Ú©Ù‡ Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´Ù‡ Ú©Ù„ Ø³ÛŒØ³ØªÙ… (Django + FastAPI + Crawler + Next.js) Ø¨Ø§ ÛŒÚ© Ø¯Ø³ØªÙˆØ± Ø§Ø¬Ø±Ø§ Ø¨Ø´Ù‡.


---

âš™ï¸ Ø¨Ø®Ø´ Ûµï¸âƒ£ â€” Docker Ùˆ Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/docker/


---

docker-compose.yml

version: '3.8'

services:
  backend:
    build: ../backend
    container_name: propanalyzer_backend
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - ../backend:/app
    ports:
      - "8000:8000"
    env_file:
      - ../.env
    depends_on:
      - db

  ai:
    build: ../ai
    container_name: propanalyzer_ai
    command: uvicorn app.main:app --host 0.0.0.0 --port 8001
    volumes:
      - ../ai:/app
    ports:
      - "8001:8001"

  crawler:
    build: ../crawler
    container_name: propanalyzer_crawler
    command: scrapy crawl divar
    volumes:
      - ../crawler:/app
    depends_on:
      - backend

  frontend:
    build: ../frontend
    container_name: propanalyzer_frontend
    command: npm run dev
    volumes:
      - ../frontend:/app
    ports:
      - "3000:3000"
    depends_on:
      - backend
      - ai

  db:
    image: postgres:14
    container_name: propanalyzer_db
    restart: always
    environment:
      POSTGRES_USER: propuser
      POSTGRES_PASSWORD: proppass
      POSTGRES_DB: propanalyzer
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:


---

nginx.conf

server {
    listen 80;

    location /api/ {
        proxy_pass http://backend:8000/;
    }

    location /ai/ {
        proxy_pass http://ai:8001/;
    }

    location / {
        proxy_pass http://frontend:3000/;
    }
}


---

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/scripts/


---

setup.sh

#!/bin/bash
echo "ğŸš€ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ PropAnalyzer..."
docker-compose up --build -d


---

update_data.sh

#!/bin/bash
echo "ğŸ•·ï¸ Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡..."
docker exec -it propanalyzer_crawler scrapy crawl divar


---

train_model.py

import pandas as pd
from sklearn.linear_model import LinearRegression
import joblib

data = pd.read_csv('data/cleaned_listings.csv')
X = data[['area', 'rooms', 'year_built']]
y = data['price']

model = LinearRegression()
model.fit(X, y)

joblib.dump(model, 'ai/app/models/price_predictor.pkl')
print("âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")


---

âš™ï¸ ÙØ§ÛŒÙ„ Ù…Ø­ÛŒØ·ÛŒ (.env.example)

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/.env.example

DEBUG=True
SECRET_KEY=your-secret-key
DB_NAME=propanalyzer
DB_USER=propuser
DB_PASSWORD=proppass
DB_HOST=db
DB_PORT=5432


---

ğŸ“˜ README.md

ğŸ“ Ù…Ø³ÛŒØ±: propanalyzer/README.md

# ğŸ  PropAnalyzer - Ù¾Ù„ØªÙØ±Ù… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ù…Ø³Ú©Ù† Ø§ÛŒØ±Ø§Ù†

Ù¾Ù„ØªÙØ±Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ØŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø§Ù…Ù„Ø§Ú©.

## ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ø§ Docker
`bash
cd docker
chmod +x ../scripts/setup.sh
../scripts/setup.sh

Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§:

Frontend â†’ http://localhost:3000

Django API â†’ http://localhost:8000/api/

AI FastAPI â†’ http://localhost:8001/

PostgreSQL â†’ localhost:5432


ğŸ¤– Ø±Ø¨Ø§Øª Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡

../scripts/update_data.sh

ğŸ§  Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„

python ../scripts/train_model.py

---

âœ…  Ú©Ø§Ù…Ù„ Ø´Ø¯:  
Backend + Crawler + AI + Frontend + Docker + Scripts




Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø±

propanalyzer/
â”‚
â”œâ”€â”€ backend/                               # Django Backend API
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ propanalyzer_api/
â”‚   â”‚   â”œâ”€â”€ init.py
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â”œâ”€â”€ wsgi.py
â”‚   â”‚   â””â”€â”€ apps/
â”‚   â”‚       â”œâ”€â”€ listings/
â”‚   â”‚       â”‚   â”œâ”€â”€ models.py
â”‚   â”‚       â”‚   â”œâ”€â”€ views.py
â”‚   â”‚       â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚       â”‚   â””â”€â”€ urls.py
â”‚   â”‚       â”œâ”€â”€ users/
â”‚   â”‚       â”‚   â”œâ”€â”€ models.py
â”‚   â”‚       â”‚   â”œâ”€â”€ views.py
â”‚   â”‚       â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚       â”‚   â””â”€â”€ urls.py
â”‚   â”‚       â”œâ”€â”€ analytics/
â”‚   â”‚       â”‚   â”œâ”€â”€ views.py
â”‚   â”‚       â”‚   â”œâ”€â”€ models.py
â”‚   â”‚       â”‚   â””â”€â”€ urls.py
â”‚   â”‚       â””â”€â”€ dashboard/
â”‚   â”‚           â”œâ”€â”€ views.py
â”‚   â”‚           â”œâ”€â”€ models.py
â”‚   â”‚           â””â”€â”€ urls.py
â”‚
â”œâ”€â”€ crawler/                               # Scrapy Crawler (Divar, Sheypoor, iHome)
â”‚   â”œâ”€â”€ scrapy.cfg
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ crawler_app/
â”‚   â”‚   â”œâ”€â”€ init.py
â”‚   â”‚   â”œâ”€â”€ items.py
â”‚   â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”‚   â”œâ”€â”€ middlewares.py
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â””â”€â”€ spiders/
â”‚   â”‚       â”œâ”€â”€ divar_spider.py
â”‚   â”‚       â”œâ”€â”€ sheypoor_spider.py
â”‚   â”‚       â””â”€â”€ ihome_spider.py
â”‚
â”œâ”€â”€ ai/                                    # FastAPI + AI Model
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ db.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze.py
â”‚   â”‚   â”‚   â””â”€â”€ undervalued.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ ai_model.py
â”‚   â”‚   â”‚   â””â”€â”€ init.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ preprocessing.py
â”‚   â”‚       â””â”€â”€ data_loader.py
â”‚
â”œâ”€â”€ frontend/                              # Next.js + Tailwind UI
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ next.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ postcss.config.js
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â””â”€â”€ globals.css
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ _app.js
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”œâ”€â”€ about.js
â”‚   â”‚   â”œâ”€â”€ dashboard.js
â”‚   â”‚   â””â”€â”€ listings/
â”‚   â”‚       â”œâ”€â”€ index.js
â”‚   â”‚       â””â”€â”€ [id].js
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ *Navbar.jsx
â”‚       â”œâ”€â”€ *Footer.jsx
â”‚       â”œâ”€â”€ *PropertyCard.jsx
â”‚       â””â”€â”€ *Charts.jsx
â”‚
â”œâ”€â”€ docker/                                # Ø§Ø¬Ø±Ø§ÛŒ Ú©Ù„ Ø³ÛŒØ³ØªÙ…
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ nginx.conf
â”‚
â”œâ”€â”€ scripts/                               # Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ùˆ Ø§ØªÙˆÙ…Ø§Ø³ÛŒÙˆÙ†
â”‚   â”œâ”€â”€ setup.sh
â”‚   â”œâ”€â”€ update_data.sh
â”‚   â””â”€â”€ train_model.py
â”‚
â”œâ”€â”€ .env.example                           # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø­ÛŒØ·ÛŒ (DB, SECRET_KEY, ...)
â”œâ”€â”€ README.md                              # ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„ Ù¾Ø±ÙˆÚ˜Ù‡
â””â”€â”€ LICENSE                                # Ù…Ø¬ÙˆØ² Ùˆ Ø­Ù‚ÙˆÙ‚